import { ResourceSource } from '../../types/common';
import { ChatConfig, GenerationConfig, LLMTool, Message, ToolsConfig } from '../../types/llm';
export declare class LLMModule {
    private controller;
    constructor({ tokenCallback, responseCallback, messageHistoryCallback, }?: {
        tokenCallback?: (token: string) => void;
        responseCallback?: (response: string) => void;
        messageHistoryCallback?: (messageHistory: Message[]) => void;
    });
    load(model: {
        modelSource: ResourceSource;
        tokenizerSource: ResourceSource;
        tokenizerConfigSource: ResourceSource;
    }, onDownloadProgressCallback?: (progress: number) => void): Promise<void>;
    setTokenCallback({ tokenCallback, }: {
        tokenCallback: (token: string) => void;
    }): void;
    configure({ chatConfig, toolsConfig, generationConfig, }: {
        chatConfig?: Partial<ChatConfig>;
        toolsConfig?: ToolsConfig;
        generationConfig?: GenerationConfig;
    }): void;
    forward(input: string): Promise<string>;
    generate(messages: Message[], tools?: LLMTool[]): Promise<string>;
    sendMessage(message: string): Promise<Message[]>;
    deleteMessage(index: number): Message[];
    interrupt(): void;
    getGeneratedTokenCount(): number;
    delete(): void;
}
//# sourceMappingURL=LLMModule.d.ts.map